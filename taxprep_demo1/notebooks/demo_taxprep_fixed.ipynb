{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# ðŸ“˜ TaxPrep Satisfaction Scorer Demo (Azure OpenAI Integration)\n",
    "# ================================================================\n",
    "\n",
    "import os, sys, pandas as pd, matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "module_path = os.path.abspath('taxprep_demo1')\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from scoring_service_azure import score_batch, derive_true_label, balance_dataframe\n",
    "\n",
    "data = [\n",
    "    {\"client_id\": 1, \"turnaround_time_days\": 8, \"error_rate_pct\": 12, \"communication_count\": 1, \"last_feedback_text\": \"Late delivery\"},\n",
    "    {\"client_id\": 2, \"turnaround_time_days\": 5, \"error_rate_pct\": 2, \"communication_count\": 4, \"last_feedback_text\": \"Great service\"},\n",
    "    {\"client_id\": 3, \"turnaround_time_days\": 9, \"error_rate_pct\": 10, \"communication_count\": 0, \"last_feedback_text\": \"No response\"},\n",
    "    {\"client_id\": 4, \"turnaround_time_days\": 4, \"error_rate_pct\": 1, \"communication_count\": 5, \"last_feedback_text\": \"Helpful advisor\"},\n",
    "    {\"client_id\": 5, \"turnaround_time_days\": 2, \"error_rate_pct\": 0.5, \"communication_count\": 6, \"last_feedback_text\": \"Quick and accurate filing\"},\n",
    "    {\"client_id\": 6, \"turnaround_time_days\": 10, \"error_rate_pct\": 15, \"communication_count\": 0, \"last_feedback_text\": \"Terrible support\"}\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df['true_label'] = df['last_feedback_text'].apply(derive_true_label)\n",
    "\n",
    "print('âœ… Original Dataset:')\n",
    "display(df)\n",
    "\n",
    "print('âš–ï¸ Balancing dataset ...')\n",
    "df_balanced = balance_dataframe(df, 'true_label')\n",
    "print(df_balanced['true_label'].value_counts())\n",
    "\n",
    "print('ðŸš€ Scoring dataset via Azure OpenAI (or fallback)...')\n",
    "scored_df = score_batch(df_balanced)\n",
    "scored_df = df_balanced.merge(scored_df, on='client_id', how='left')\n",
    "scored_df['pred_label'] = scored_df['label']\n",
    "\n",
    "print('âœ… Scoring complete:')\n",
    "display(scored_df)\n",
    "\n",
    "y_true = scored_df['true_label']\n",
    "y_pred = scored_df['pred_label']\n",
    "print('\\nðŸ“Š Evaluation Metrics:')\n",
    "print(classification_report(y_true, y_pred, zero_division=0))\n",
    "\n",
    "labels = ['Satisfied', 'Dissatisfied']\n",
    "cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels).plot(cmap='Blues', values_format='d')\n",
    "plt.title('Customer Satisfaction Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "print('\\nðŸ” Sample Predictions:')\n",
    "for _, row in scored_df.iterrows():\n",
    "    print(f\"{row['client_id']:>2} | True: {row['true_label']:<13} | Pred: {row['pred_label']:<13} | Feedback: {row['last_feedback_text']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
